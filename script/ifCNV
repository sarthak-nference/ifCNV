import os
import re
import numpy as np
import pandas as pd
import subprocess
from sklearn.ensemble import IsolationForest
import plotly
import plotly.graph_objs as go
from pybedtools import BedTool
import argparse


###########################################
#            CNV Module Functions         #
###########################################
def generateReport(final, output_dir, reads, ressources, CNVneg):
    if not os.path.isdir(output_dir):
        os.makedirs(output_dir)

    cmd = ["cp", "-r", ressources, output_dir]
    subprocess.check_output(cmd)

    output_report = f"{output_dir}/run.html"
    html = getTemplate()

    for i in final.index:
        fff = final.loc[i]

        run = fff['Run']
        sample = fff['Sample name']
        region = fff['Region']

        generateGraph(sample, output_dir, reads, region, CNVneg)

        ratio = str(round(fff['Reads ratio'], 2))
        score = str(round(fff['Score'], 2))

        html = html.replace('<!--ADD RUN-->', '<!--ADD RUN-->\n\t\t\t<!--ADD RUN-->')

        torep = (
            f'<tr url="{sample}_{region}.html" style="cursor: pointer;">'
            f'<td>{run}</td>'
            f'<td>{sample}</td>'
            f'<td>{region}</td>'
            f'<td>{ratio}</td>'
            f'<td>{score}</td></tr>'
        )
        html = html.replace('<!--ADD RUN-->', torep, 1)
        with open(output_report, "w") as FH_out:
            FH_out.write(html)


def generateGraph(sample, output_dir, reads, region, CNVneg):
    dfneg = np.mean(reads[CNVneg], axis=1)
    dfpos = reads[sample]

    df = np.log2(np.array(dfpos) / np.array(dfneg))

    genes = [i.split("_")[0] for i in reads.index]

    col = []
    for i in reads.index:
        if i.startswith(f"{region}_"):
            col.append("red")
        else:
            col.append("black")

    data = [go.Scatter(
        x=genes,
        y=df,
        mode='markers',
        marker=dict(color=col, size=10)
    )]
    layout = go.Layout(
        yaxis=dict(title='Nomalized reads ratio'),
        plot_bgcolor='rgb(240,240,240)'
    )
    fig = go.Figure(data=data, layout=layout)
    plotly.offline.plot(
        fig,
        filename=f"{output_dir}/{sample}_{region}.html",
        auto_open=False
    )


def getTemplate():
    html = """
<!DOCTYPE html>
<html>
  <head>
    <title>ifCNV</title>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="ressources/lib///w3.css" />
    <link rel="stylesheet" href="ressources/fontawesome-free-5.3.1-web/css/all.css" />
    <link rel="stylesheet" href="ressources/lib///datatables/datatables.min.css" />
    <link rel="stylesheet" href="ressources/lib///interface.css" />
  </head>
  <body>
    <!-- Top container -->
    <div class="w3-bar w3-top w3-blue-grey w3-large" style="margin-left:10px;">
      <img src="ressources/ifCNV.png" width="170" height="80">
      <span style="color:white" class="w3-display-middle"><b><i><font size="+20" face="calibri">ifCNV Report</font></i></b></span>
    </div>
  <body>
    <div id="Summary" class="w3-container" style="margin-left:50px;margin-top:125px;">
      <h2>
        <b><center>Results</center></b>
      </h2>

    <div class="w3-main" style="margin-left:100px;margin-right:100px;">
        <div id="runs" class="w3-container" style="padding-top:10px;">
          <table id="T_runs" class="w3-table-all w3-hoverable w3-centered">
            <thead>
              <tr>
                <th>Run</th>
                <th>Sample Name</th>
                <th>Region</th>
                <th>Reads ratio</th>
                <th>Score</th>
              </tr>
            </thead>
            <tbody>
                                <!--ADD RUN-->
            </tbody>
            <tfoot class="" style="">
              <tr class="" style="">
                <th>Run</th>
                <th>Sample Name</th>
                <th>Region</th>
                <th>Reads ratio</th>
                <th>Score</th>
              </tr>
            </tfoot>
          </table>
        </div>
    </div>
</body>

<script type="text/javascript" src="ressources/lib/datatables/datatables.min.js"></script>
  <script>
  $('body').on('mousedown', 'tr[url]', function(e){
      var click = e.which;
      var url = $(this).attr('url');
      if(url){
          if(click == 2 || (click == 1 && (e.ctrlKey || e.metaKey))){
              window.open(url, '_blank');
              window.focus();
          }
          else if(click == 1){
              window.location.href = url;
          }
          return true;
      }
  });

            $(document).ready(function() {
                $('#T_runs tfoot th').each( function () {
                    var title = $(this).text();
                    $(this).html( '<input type="text" placeholder="Search '+title+'" style="width:100%" />' );
                } );

                var table = $('#T_runs').DataTable({
                    paging:true,
                    order: [[1, 'desc']],
                });

                table.columns().every( function () {
                    var that = this;

                    $( 'input', this.footer() ).on( 'keyup change', function () {
                        if ( that.search() !== this.value ) {
                            that
                                .search( this.value )
                                .draw();
                        }
                    });
                });
            });
        </script>

</html>
    """
    return html


def replaceZeroes(data):
    min_nonzero = np.min(data[np.nonzero(data)])
    data[data == 0] = min_nonzero
    return data


def createReadsMatrix(pathToBam, bedFile, output=None, verbose=False):
    cmd = ["ls", pathToBam]
    res = subprocess.check_output(cmd)
    final = pd.DataFrame()

    bed = BedTool(bedFile)

    for i in res.decode('utf-8').split("\n"):
        if i.endswith(".bam"):
            sampleName = i[:-4]
            if verbose:
                print(f"Processing sample {sampleName}...")
            try:
                pathBam = pathToBam + "/" + i
                data = bed.multi_bam_coverage(bams=pathBam)
                df = data.to_dataframe()
                final[sampleName] = df[df.keys()[len(df.columns) - 1]]
                if verbose:
                    print(f"{sampleName} Done \n")
            except subprocess.CalledProcessError:
                print(f"{sampleName} : skipped")
                print("Hint: Index file (.bai) must be present in the folder \n")

    final.index = list(df["name"])

    if output is not None:
        if verbose:
            print("Reads matrix created !")
        final.to_csv(output, sep="\t")

    return final


def filterReads(reads, N, regtar=None, regsamp=None):
    col = reads.columns
    rows = reads.index
    if regtar is not None:
        reads = reads.filter(regex=regtar, axis=0)
    if regsamp is not None:
        reads = reads.filter(regex=f"^(?!{regsamp})")
    reads = reads.filter(regex="^(?!MSI)", axis=0)
    reads = reads.filter(regex="^(?!TN)")
    reads = reads.filter(regex="^(?!TP)")
    reads = reads.filter(regex="^(?!HD)")
    reads = reads.filter(regex="^(?!H2)")
    reads = reads.loc[reads.sum(axis=1) / len(reads.columns) > N, :]
    filtered_samples = col[~np.in1d(col, reads.columns)]
    filtered_targets = rows[~np.in1d(rows, reads.index)]
    return (reads, filtered_samples, filtered_targets)


def normalizeReads(reads):
    reads_norm = reads / reads.sum(axis=0)
    return reads_norm


def aberrantSamples(reads, conta='auto', verbose=True):
    if conta != 'auto' and conta != 'none':
        conta = float(conta)
    if conta == 'none':
        conta = 1 / reads.shape[1]

    tmp = np.percentile(reads, 99, axis=0) / np.mean(reads, axis=0)
    random_data = np.array(tmp).reshape(-1, 1)
    clf = IsolationForest(contamination=conta).fit(random_data)
    preds = clf.predict(random_data)
    res_amp = np.array(reads.columns)[preds == -1]

    tmp = np.percentile(reads, 1, axis=0) / np.mean(reads, axis=0)
    random_data = np.array(tmp).reshape(-1, 1)
    clf = IsolationForest(contamination=conta).fit(random_data)
    preds = clf.predict(random_data)
    res_del = np.array(reads.columns)[preds == -1]

    res = np.unique(np.concatenate((res_amp, res_del)))
    norm = np.array(reads.columns[~np.in1d(reads.columns, res)])

    if verbose:
        print("Aberrant sample(s): \n")
        for i in res:
            print(f"\t{i}\n")

        print("Normal sample(s): \n")
        for i in norm:
            print(f"\t{i}\n")

    return (res, norm)

def load_bed(bedFile):
    try:
        with open(bedFile, 'r') as f:
            content = f.readlines()
        content = [line.strip() for line in content]
    except IOError as e:
        print(f"Error opening BED file {bedFile}: {e}")
        return None

    data = []
    for line in content:
        try:
            fields = line.split()
            if len(fields) < 3:
                raise ValueError(f"Invalid BED line: {line}")
            chrom, start, end = fields[:3]
            start, end = int(start), int(end)
            if start > end:
                raise ValueError(f"Start position {start} is greater than end position {end} in line: {line}")
            data.append([chrom, start, end])
        except ValueError as e:
            print(f"Skipping invalid BED line: {e}")
            continue

    return pd.DataFrame(data, columns=["chrom", "start", "end"])


def process_bam_files(bam_file_paths):
    processed_data = []
    for file_path in bam_file_paths:
        try:
            cmd = ['samtools', 'view', '-F', '4', file_path]
            output = subprocess.check_output(cmd)
            processed_data.append(output.decode('utf-8'))
        except subprocess.CalledProcessError as e:
            print(f"Error processing BAM file {file_path}: {e}")
            continue
    return processed_data

def aberrantAmpliconsPerSample(name, reads_norm, CNVneg, conta=0.01):
    if conta != 'auto':
        if conta != 'none':
            conta = float(conta)
    if conta == 'none':
        conta = 1 / reads.shape[1]
    random_data = np.array(reads_norm[name])
    random_data = replaceZeroes(random_data)
    norm = np.array(np.mean(reads_norm[CNVneg], axis=1))
    norm = replaceZeroes(norm)
    df = np.log2(random_data / norm)
    clf = IsolationForest(contamination=conta).fit(df.reshape(-1, 1))
    preds = clf.predict(df.reshape(-1, 1))

    return np.array(reads_norm.index)[preds == -1]


def scoreAmplif(k, n, N):
    p = n / N
    x = np.log(1 / ((p**k) * (1 - p)**(n - k))) * (k / n)
    return x


def amplifEvalGene(reads_norm, region, CNVneg, sample):
    reads_m = reads_norm.filter(regex=f"^{region}", axis=0)
    pos = np.array(reads_m[sample])
    norm = np.array(np.mean(reads_m[CNVneg], axis=1))
    df = pos / norm
    val = np.mean(df)
    if val == np.inf:
        val = 100

    return val


def aberrantAmpliconsFinal(reads, reads_norm, CNVpos, CNVneg, scoreThreshold=10, conta=0.01, mode="fast", run="ifCNV", verbose=True):
    f = pd.DataFrame(columns=["Run", "Sample name", "Region", "Reads ratio", "Score"])

    if mode == "extensive":
        samples = [*CNVpos, *CNVneg]
    if mode == "fast":
        samples = CNVpos

    q = 0
    for name in samples:
        abAmp = aberrantAmpliconsPerSample(name, reads_norm, CNVneg, conta=conta)
        if abAmp.shape != (0, ):
            genes = np.unique([i.split('_')[0] for i in abAmp])
            for gene in genes:
                r = re.compile(gene)
                abEx = list(filter(r.match, abAmp))
                tmp = reads.filter(regex=f"^{gene}", axis=0)

                score = scoreAmplif(len(abEx), tmp.shape[0], reads.shape[0])
                amplif = amplifEvalGene(reads_norm, gene, CNVneg, name)

                if score > scoreThreshold:
                    f.loc[q] = [run, name, gene, amplif, score]
                    q = q + 1
    if verbose:
        print(f"{str(f.shape[0])} aberrant regions found in {str(len(np.unique(f['Sample name'])))} samples.\n")

    return f

def resource_path(relative_path):
    """ Get the absolute path to a resource, handling PyInstaller's _MEIPASS """
    if getattr(sys, '_MEIPASS', False):
        # Running in PyInstaller bundle
        return os.path.join(sys._MEIPASS, relative_path)
    else:
        # Running in normal Python environment
        return os.path.join(os.path.abspath("."), relative_path)
###############################################################################
#
# MAIN
#
###############################################################################
def main(args):
    # Determine the path to the ressources directory
    if args.lib_ressources is None:
        lib_ressources = resource_path("CNV/ressources")
    else:
        lib_ressources = args.lib_ressources

    # Create or open the reads matrix
    if args.skip is None:
        reads = createReadsMatrix(pathToBam=args.input, bedFile=args.bed, verbose=args.verbose, output=args.readsMatrixOuptut)
    else:
        reads = pd.read_csv(args.skip, sep="\t", index_col=0)

    # Filter the reads matrix
    filteredReads, filteredS, filteredT = filterReads(reads=reads, N=args.minReads, regtar=args.regTargets, regsamp=args.regSample)

    if args.verbose:
        if len(filteredS) > 0:
            print("Filtered samples:")
            for i in filteredS:
                print(i)

    # Normalize the reads matrix
    normReads = normalizeReads(filteredReads)

    # Find the aberrant samples
    CNVpos, CNVneg = aberrantSamples(filteredReads, conta=args.contaSamples, verbose=args.verbose)

    # Find the aberrant targets
    final = aberrantAmpliconsFinal(filteredReads, normReads, CNVpos, CNVneg, scoreThreshold=args.scoreThreshold, conta=args.contaTargets, mode=args.mode, run=args.run, verbose=args.verbose)

    if args.save:
        if not os.path.isdir(args.output):
            cmd = ["mkdir", args.output]
            subprocess.check_output(cmd)
        final.to_csv(f"{args.output}/{args.run}.tsv", sep="\t")

    # Generate the report
    generateReport(final, output_dir=args.output, reads=normReads, ressources=lib_ressources, CNVneg=CNVneg)

    if args.verbose:
        print("ifCNV analysis done successfully!\n")

    if args.autoOpen:
        try:
            os.startfile(f"{args.output}/run.html")
        except AttributeError:
            try:
                subprocess.call(['open', f"{args.output}/run.html"])
            except:
                print('Could not open URL')
###############################################################################
#
# MAIN ENTRY POINT
#
###############################################################################
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='ifCNV')

    group_mandatory = parser.add_argument_group('Mandatory')
    group_mandatory.add_argument(
        '-i',
        '--input',
        type=str,
        help='Path to the input bam folder',
        required=True
    )
    group_mandatory.add_argument(
        '-b',
        '--bed',
        type=str,
        help='Path to the bed file',
        required=True
    )
    group_mandatory.add_argument(
        '-o',
        '--output',
        type=str,
        help='Path to the output report',
        required=True
    )

    parser.add_argument(
        '-s',
        '--skip',
        type=str,
        default=None,
        help='A path to the reads matrix'
    )
    parser.add_argument(
        '-m',
        '--mode',
        type=str,
        default='fast',
        help='fast or extensive'
    )
    parser.add_argument(
        '-rm',
        '--readsMatrixOuptut',
        type=str,
        default=None,
        help='A path to a file to export the reads matrix as a .tsv file'
    )
    parser.add_argument(
        '-min',
        '--minReads',
        type=int,
        default=10,
        help='Min mean reads per target'
    )
    parser.add_argument(
        '-cs',
        '--contaSamples',
        default="auto",
        help='Contamination parameter for the AberrantSamples function'
    )
    parser.add_argument(
        '-ct',
        '--contaTargets',
        default=0.05,
        help='Contamination parameter for the AberrantTargets function'
    )
    parser.add_argument(
        '-sT',
        '--scoreThreshold',
        type=int,
        default=10,
        help='Threshold on the localisation score'
    )
    parser.add_argument(
        '-rS',
        '--regSample',
        type=str,
        default=None,
        help='A pattern for removing controls'
    )
    parser.add_argument(
        '-rT',
        '--regTargets',
        type=str,
        default=None,
        help='A pattern for removing targets'
    )
    parser.add_argument(
        '-v',
        '--verbose',
        type=bool,
        default=True,
        help='A boolean'
    )
    parser.add_argument(
        '-a',
        '--autoOpen',
        type=bool,
        default=True,
        help='A boolean'
    )
    parser.add_argument(
        '-r',
        '--run',
        type=str,
        default="ifCNV",
        help='The name of the experiment'
    )
    parser.add_argument(
        '-sv',
        '--save',
        type=bool,
        default=False,
        help='A boolean, if True, saves the results in a .tsv file'
    )
    parser.add_argument(
        '-l',
        '--lib-ressources',
        type=str,
        default=None,
        help='Path where lib to import for report.'
    )

    args = parser.parse_args()
    main(args)
